name: dashboard-10min

on:
  workflow_dispatch: {}
  schedule:
    - cron: "*/7 12 * * 1-5"
    - cron: "*/7 13-20 * * 1-5"

jobs:
  tenmin:
    name: Build and Publish Intraday
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write
    concurrency:
      group: dashboard-10min
      cancel-in-progress: true
    env:
      TZ: America/Phoenix
      LIVE_BRANCH: data-live-10min
      PYTHONUNBUFFERED: "1"

    steps:
      # -------------------- setup --------------------
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install requests python-dateutil

      # -------------------- SECTORS: build â†’ normalize â†’ validate --------------------
      - name: Build sectorCards source (10m)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          mkdir -p data
          # This may write different shapes; we'll normalize next.
          python -u scripts/build_outlook_source_from_polygon.py --mode intraday10 --out data/outlook_source.json || true
          echo "----- RAW SOURCE (first 80 lines) -----" || true
          head -n 80 data/outlook_source.json || true

      - name: Normalize sectorCards source â†’ schema v1
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, sys, re

          PATH = "data/outlook_source.json"
          try:
            j = json.load(open(PATH, "r", encoding="utf-8"))
          except Exception:
            # if file missing or unreadable, produce empty skeleton so validator will fail meaningfully
            j = {}

          # try common nests/keys
          candidates = []
          if isinstance(j, dict):
            if isinstance(j.get("sectorCards"), list): candidates = j["sectorCards"]
            elif isinstance(j.get("data",{}).get("sectorCards"), list): candidates = j["data"]["sectorCards"]
            elif isinstance(j.get("sectors"), list): candidates = j["sectors"]
            elif isinstance(j.get("cards"), list): candidates = j["cards"]

          # field alias map
          def num(x):
            try: return float(x)
            except: return None
          def to_card(c):
            sector = c.get("sector") or c.get("name") or c.get("label")
            if not sector: return None
            # allow alternate names
            bp = c.get("breadth_pct", c.get("breadth", c.get("breadthPercent")))
            mp = c.get("momentum_pct", c.get("momentum", c.get("momentumPercent")))
            nh = c.get("nh", c.get("newHighs"))
            nl = c.get("nl", c.get("newLows"))
            up = c.get("up", c.get("advancers"))
            dn = c.get("down", c.get("decliners", c.get("dn")))
            card = {
              "sector": str(sector),
              "breadth_pct": num(bp),
              "momentum_pct": num(mp),
              "nh": int(nh or 0),
              "nl": int(nl or 0),
              "up": int(up or 0),
              "down": int(dn or 0),
            }
            # if percentages missing but counts present, compute
            if card["breadth_pct"] is None:
              den = card["nh"] + card["nl"]
              card["breadth_pct"] = (100.0 * card["nh"] / den) if den else 0.0
            if card["momentum_pct"] is None:
              den = card["up"] + card["down"]
              card["momentum_pct"] = (100.0 * card["up"] / den) if den else 0.0
            return card

          normalized = []
          for c in candidates or []:
            try:
              nc = to_card(c)
              if nc and nc["sector"]:
                normalized.append(nc)
            except Exception:
              continue

          # canonical order helper
          ORDER = [
            "information technology","materials","health care","communication services",
            "real estate","energy","consumer staples","consumer discretionary",
            "financials","utilities","industrials",
          ]
          def norm(s): return (s or "").strip().lower()
          alias = {
            "healthcare":"health care","health-care":"health care",
            "info tech":"information technology","technology":"information technology","tech":"information technology",
            "communications":"communication services","comm services":"communication services","telecom":"communication services",
            "staples":"consumer staples","discretionary":"consumer discretionary",
            "finance":"financials","industry":"industrials","reit":"real estate","reits":"real estate",
          }

          # squash to canonical 11 keys if we have more
          bykey = {}
          for c in normalized:
            k = alias.get(norm(c["sector"]), norm(c["sector"]))
            if k not in bykey: bykey[k] = c | {"sector": k.title()}
            else:
              # merge duplicates by averaging pct and summing counts
              a, b = bykey[k], c
              a["nh"] += b["nh"]; a["nl"] += b["nl"]; a["up"] += b["up"]; a["down"] += b["down"]
              # recompute pct from counts
              den = a["nh"] + a["nl"]; a["breadth_pct"] = (100.0*a["nh"]/den) if den else 0.0
              den = a["up"] + a["down"]; a["momentum_pct"] = (100.0*a["up"]/den) if den else 0.0

          sectorCards = []
          for name in ORDER:
            if name in bykey:
              sectorCards.append(bykey[name])
            else:
              # impute empty sector to keep length=11
              sectorCards.append({"sector": name.title(), "breadth_pct": 0.0, "momentum_pct": 0.0, "nh": 0, "nl": 0, "up": 0, "down": 0})

          out = { "sectorCards": sectorCards }
          with open(PATH, "w", encoding="utf-8") as f:
            json.dump(out, f, ensure_ascii=False, separators=(",",":"))
          print(f"[normalize] sectorCards={len(sectorCards)}  IT_b={sectorCards[0]['breadth_pct']:.2f} IT_m={sectorCards[0]['momentum_pct']:.2f}")
          PY

      - name: Validate sectorCards source
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, sys
          j = json.load(open("data/outlook_source.json","r",encoding="utf-8"))
          cards = j.get("sectorCards") or []
          need  = ("sector","breadth_pct","momentum_pct","nh","nl","up","down")
          ok = (len(cards)==11 and all(k in cards[0] for k in need))
          if not ok:
            print(f"[sectors] INVALID source: cards={len(cards)} need={need}"); sys.exit(2)
          print(f"[sectors] OK cards=11 | IT b={cards[0]['breadth_pct']} m={cards[0]['momentum_pct']}")
          PY

      # -------------------- DASHBOARD (uses the fresh source) --------------------
      - name: Build intraday payload
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          mkdir -p data
          python -u scripts/make_dashboard.py \
            --mode intraday \
            --source data/outlook_source.json \
            --out data/outlook_intraday.json

      - name: Alias intraday metrics
        run: |
          python -u scripts/alias_intraday_metrics.py --in data/outlook_intraday.json --out data/outlook_intraday.json

      - name: Repair intraday neutrals and add display fields
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          if [ -n "${POLYGON_API_KEY:-}" ]; then
            python -u scripts/repair_intraday_metrics_10m.py --in data/outlook_intraday.json --out data/outlook_intraday.json
          else
            echo "POLYGON_API_KEY missing, skipping neutral repair"
          fi

      - name: Repair meter from counts
        run: |
          python -u scripts/repair_meter_from_counts.py --in data/outlook_intraday.json --out data/outlook_intraday.json

      - name: Finalize breadth (restore 60/40 blend)
        run: |
          python -u scripts/finalize_intraday_breadth.py --in data/outlook_intraday.json --out data/outlook_intraday.json

      - name: Print meter snapshot
        run: |
          python - <<'PY'
          import json
          j=json.load(open("data/outlook_intraday.json","r",encoding="utf-8"))
          m=j.get("metrics",{}) or {}; it=j.get("intraday",{}) or {}; ov=(it.get("overall10m") or {})
          snap={"updated_at":j.get("updated_at"),"breadth_final":m.get("breadth_pct"),
                "align_raw":m.get("breadth_align_pct"),"align_fast":m.get("breadth_align_pct_fast"),
                "bar_raw":m.get("breadth_bar_pct"),"bar_fast":m.get("breadth_bar_pct_fast"),
                "breadth_slow":m.get("breadth_slow_pct"),"momentum_combo":m.get("momentum_combo_pct"),
                "volatility_pct":m.get("volatility_pct"),"overall":{"state":ov.get("state"),"score":ov.get("score")}}
          print("ðŸ”Ž snapshot:", snap)
          PY

      # -------------------- publish --------------------
      - name: Write heartbeat
        run: |
          date -u +'%Y-%m-%dT%H:%M:%SZ' > data/heartbeat_10min.txt

      - name: Stage artifacts
        run: |
          mkdir -p /tmp/live10
          cp -f data/outlook_intraday.json /tmp/live10/outlook_intraday.json
          cp -f data/heartbeat_10min.txt   /tmp/live10/heartbeat_10min.txt

      - name: Prepare live branch
        run: |
          git config user.name "actions-bot"
          git config user.email "bot@users.noreply.github.com"
          git reset --hard
          git clean -fdx
          if git ls-remote --exit-code --heads origin "${LIVE_BRANCH}" >/dev/null 2>&1; then
            git fetch origin "${LIVE_BRANCH}"
            git checkout -B "${LIVE_BRANCH}" "origin/${LIVE_BRANCH}"
          else
            git checkout --orphan "${LIVE_BRANCH}"
          fi
          find . -mindepth 1 -maxdepth 1 ! -name ".git" -exec rm -rf {} +
          mkdir -p data
          cp -f /tmp/live10/outlook_intraday.json data/outlook_intraday.json
          cp -f /tmp/live10/heartbeat_10min.txt data/heartbeat_10min.txt

      - name: Commit and push live branch
        run: |
          git add data
          git commit -m "10m live $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "nothing to commit"
          git push origin "${LIVE_BRANCH}" --force

      - name: Trigger Render deploy
        if: ${{ success() }}
        env:
          RENDER_DEPLOY_HOOK: ${{ secrets.RENDER_DEPLOY_HOOK_BACKEND1 }}
        run: |
          if [ -n "${RENDER_DEPLOY_HOOK:-}" ]; then
            curl -fsS -X POST "${RENDER_DEPLOY_HOOK}"
          else
            echo "No Render deploy hook secret found. Skipping deploy."
          fi
