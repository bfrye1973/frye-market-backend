name: dashboard-10min

on:
  workflow_dispatch: {}
  schedule:
    # Pre-open warmup (exactly 1h before 13:30 UTC open): 12:30, 12:40, 12:50 UTC (Mon–Fri)
    - cron: "30-59/10 12 * * 1-5"
    # Regular Trading Hours: every 10 minutes 13:00–20:59 UTC (Mon–Fri)
    - cron: "*/10 13-20 * * 1-5"

jobs:
  tenmin:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    concurrency:
      group: dashboard-10min
      cancel-in-progress: true
    permissions:
      contents: write
    env:
      TZ: America/Phoenix
      LIVE_BRANCH: data-live-10min
      PYTHONUNBUFFERED: "1"
      FD_MAX_WORKERS: "16"
      FD_SNAPSHOT_BATCH: "250"

    steps:
      # --------------------- Repo & Python setup ---------------------
      - name: Checkout (shallow)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (if any)
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Mark start time
        run: |
          echo "START_TS_UTC=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "$GITHUB_ENV"
          echo "START_EPOCH=$(date -u +%s)" >> "$GITHUB_ENV"
          echo "[start] UTC=$(date -u +%T)  local=$(date +%T)"

      # --------------------- FAST BUILD (no archives) ---------------------
      - name: Build outlook source (intraday10 FAST, step timeout 18m)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          echo "[timing] build_outlook_source START $(date -u +%T)"
          timeout 1080s python -u scripts/build_outlook_source_from_polygon.py --mode intraday10
          echo "[timing] build_outlook_source END   $(date -u +%T)"
          test -s data/outlook_source.json

      # --------------------- SANITIZE: drop any in-flight 10m bar ---------------------
      # Why: EMA cross must use CLOSED bars only (fixes false 'bull' reads mid-bar).
      # This is schema-tolerant: it removes the last element of any "bars" array that
      # looks like OHLCV bars if its timestamp aligns with the current (still-open) bucket.
      - name: Ensure CLOSED bars only (no in-flight)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, sys, time, math, pathlib
          p = pathlib.Path("data/outlook_source.json")
          js = json.loads(p.read_text())
          now = int(time.time())
          # 10-minute bucket length
          BUCKET = 600
          # the *current* bucket start (still open until it closes)
          current_bucket_start = (now // BUCKET) * BUCKET
          removed = 0

          def looks_like_bar(o):
            if not isinstance(o, dict): return False
            keys = set(o.keys())
            # tolerate t or time, o/h/l/c or open/high/low/close
            has_t = ("t" in keys) or ("time" in keys)
            has_prices = any(k in keys for k in ("o","open")) and any(k in keys for k in ("h","high")) \
                         and any(k in keys for k in ("l","low")) and any(k in keys for k in ("c","close"))
            return has_t and has_prices

          def bar_ts(o):
            if "t" in o: return int(o["t"] // 1000) if o["t"] > 2_000_000_000 else int(o["t"])
            if "time" in o: return int(o["time"] // 1000) if o["time"] > 2_000_000_000 else int(o["time"])
            return None

          def maybe_drop_last_bars(container):
            nonlocal removed
            if not isinstance(container, list) or len(container) < 1: return
            last = container[-1]
            if not looks_like_bar(last): return
            ts = bar_ts(last)
            if ts is None: return
            # if the last bar belongs to the *current* (still-open) bucket, drop it
            if (ts // BUCKET) * BUCKET == current_bucket_start:
              container.pop()
              removed += 1

          # Walk all arrays named "bars" anywhere in the tree
          def walk(x):
            if isinstance(x, dict):
              for k,v in list(x.items()):
                if k.lower() == "bars" and isinstance(v, list):
                  maybe_drop_last_bars(v)
                else:
                  walk(v)
            elif isinstance(x, list):
              for v in x: walk(v)

          walk(js)
          p.write_text(json.dumps(js, separators=(",",":")))
          print(f"[sanitize] removed_inflight_arrays={removed}")
          PY

      - name: Make dashboard payload (intraday)
        run: |
          set -euo pipefail
          echo "[timing] make_dashboard START $(date -u +%T)"
          python -u scripts/make_dashboard.py --mode intraday --source data/outlook_source.json --out data/outlook_intraday.json
          echo "[timing] make_dashboard END   $(date -u +%T)"
          jq -r '.metrics.ema_cross as $x | "ema_cross=" + ($x//"n/a") + "  ema10_dist_pct=" + ((.metrics.ema10_dist_pct//0|tonumber)|tostring) + "  updated_at=" + ((.updated_at//.updated_at_utc//"n/a")|tostring)' data/outlook_intraday.json || true

      - name: Write heartbeat_10min
        run: |
          set -e
          mkdir -p data
          date -u +'%Y-%m-%dT%H:%M:%SZ' > data/heartbeat_10min.txt

      # --------------------- Stage LIVE artifacts (to /tmp) ---------------------
      - name: Stage LIVE artifacts
        run: |
          set -e
          mkdir -p /tmp/live10
          cp -f data/outlook_intraday.json /tmp/live10/outlook_intraday.json
          cp -f data/heartbeat_10min.txt   /tmp/live10/heartbeat_10min.txt
          if [ -f data/outlook_source.json ]; then cp -f data/outlook_source.json /tmp/live10/outlook_source.json; fi

      # --------------------- Freshness gate ---------------------
      - name: Skip publish if a newer LIVE exists
        env:
          LIVE_RAW_URL: https://raw.githubusercontent.com/bfrye1973/frye-market-backend/data-live-10min/data/outlook_intraday.json
        run: |
          set -e
          OUR_TS=$(jq -r '.updated_at // .updated_at_utc // .timestamp // empty' /tmp/live10/outlook_intraday.json || true)
          if [ -z "$OUR_TS" ]; then
            echo "Could not read OUR_TS from payload; continuing publish"
            exit 0
          fi
          curl -sfL "${LIVE_RAW_URL}?t=$(date +%s)" -o /tmp/live10/current_live.json || true
          CUR_TS=$(jq -r '.updated_at // .updated_at_utc // .timestamp // empty' /tmp/live10/current_live.json 2>/dev/null || true)
          echo "our payload updated_at:  $OUR_TS"
          echo "live branch updated_at: $CUR_TS"
          if [ -n "$CUR_TS" ]; then
            A=$(date -u -d "$OUR_TS" +%s 2>/dev/null || date -u -d "${OUR_TS/Z/+00:00}" +%s 2>/dev/null || echo 0)
            B=$(date -u -d "$CUR_TS" +%s 2>/dev/null || date -u -d "${CUR_TS/Z/+00:00}" +%s 2>/dev/null || echo 0)
            echo "epoch ours=$A live=$B"
            if [ "$B" -ge "$A" ]; then
              echo "[gate] Newer or equal LIVE already present; skipping publish."
              echo "SKIP_PUBLISH=1" >> "$GITHUB_ENV"
            fi
          fi

      # --------------------- Publish LIVE branch safely ---------------------
      - name: Push LIVE branch (10min)
        if: env.SKIP_PUBLISH != '1'
        run: |
          set -e
          git config user.name  "actions-user"
          git config user.email "actions@github.com"

          git reset --hard
          git clean -fdx

          git fetch origin "${LIVE_BRANCH}" || true
          if git ls-remote --exit-code --heads origin "${LIVE_BRANCH}" >/dev/null 2>&1; then
            git checkout -B "${LIVE_BRANCH}" "origin/${LIVE_BRANCH}"
          else
            git checkout --orphan "${LIVE_BRANCH}"
          fi

          find . -mindepth 1 -maxdepth 1 ! -name ".git" -exec rm -rf {} +

          mkdir -p data
          cp -f /tmp/live10/* data/

          git add data
          git commit -m "10m live @ $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "nothing to commit"
          git push origin "${LIVE_BRANCH}"
