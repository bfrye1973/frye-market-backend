name: dashboard-10min

on:
  workflow_dispatch: {}
  schedule:
    # Pre-open warmup (12:00–12:59 UTC) every 7 min, Mon–Fri
    - cron: "*/7 12 * * 1-5"
    # RTH (13:00–20:59 UTC) every 7 min, Mon–Fri
    - cron: "*/7 13-20 * * 1-5"

jobs:
  tenmin:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    concurrency:
      group: dashboard-10min
      cancel-in-progress: true
    permissions:
      contents: write
    env:
      TZ: America/Phoenix
      LIVE_BRANCH: data-live-10min
      PYTHONUNBUFFERED: "1"
      FD_MAX_WORKERS: "16"
      FD_SNAPSHOT_BATCH: "250"

    steps:
      # --------------------- Repo & Python setup ---------------------
      - name: Checkout (shallow)
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps (if any)
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      - name: Mark start time
        run: |
          echo "START_TS_UTC=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> "$GITHUB_ENV"
          echo "START_EPOCH=$(date -u +%s)" >> "$GITHUB_ENV"
          echo "[start] UTC=$(date -u +%T)  local=$(date +%T)"

      # --------------------- FAST BUILD (no archives) ---------------------
      - name: Build outlook source (intraday10 FAST, step timeout 18m)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          echo "[timing] build_outlook_source START $(date -u +%T)"
          timeout 1080s python -u scripts/build_outlook_source_from_polygon.py --mode intraday10
          echo "[timing] build_outlook_source END   $(date -u +%T)"
          test -s data/outlook_source.json

      # --------------------- Fallback: ensure SPY 10m bars exist ---------------------
      # If the source JSON doesn't contain a SPY 10m bar array (>= 25 bars),
      # fetch them from Polygon and inject under series.SPY_10m.bars
      - name: Ensure SPY 10m bars present (fallback inject)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, os, sys, time, urllib.request
          from datetime import datetime, timedelta, timezone

          SRC = "data/outlook_source.json"
          with open(SRC, "r", encoding="utf-8") as f:
            js = json.load(f)

          # probe for any plausible SPY 10m bars list (>=25)
          def looks_bar(o):
            if not isinstance(o, dict): return False
            k = set(o.keys())
            return (("t" in k or "time" in k) and
                    (("o" in k or "open" in k) and ("h" in k or "high" in k) and
                     ("l" in k or "low"  in k) and ("c" in k or "close" in k)))

          def find_bars(obj):
            stack=[obj]; best=None
            while stack:
              x=stack.pop()
              if isinstance(x, dict):
                sym=str(x.get("symbol","")).upper()
                tf=str(x.get("timeframe","")).lower()
                bars=x.get("bars")
                if isinstance(bars,list) and len(bars)>=25:
                  if sym=="SPY" and ("10" in tf or "10m" in tf or "10-min" in tf):
                    return bars
                  if best is None: best=bars
                stack.extend(x.values())
              elif isinstance(x,list):
                stack.extend(x)
            return best

          bars = find_bars(js)
          if bars and len(bars) >= 25:
            print(f"[probe] found existing bars: {len(bars)}"); 
          else:
            print("[probe] no SPY 10m bars found; injecting from Polygon…")
            key = os.environ.get("POLYGON_API_KEY")
            if not key: 
              print("No POLYGON_API_KEY; cannot inject.", file=sys.stderr)
              sys.exit(1)

            # fetch last ~3 days to be safe
            end = datetime.utcnow().date()
            start = end - timedelta(days=3)
            url  = f"https://api.polygon.io/v2/aggs/ticker/SPY/range/10/minute/{start}/{end}?adjusted=true&sort=asc&limit=50000&apiKey={key}"
            req  = urllib.request.Request(url, headers={"User-Agent":"inject-bars/1.0"})
            with urllib.request.urlopen(req, timeout=30) as resp:
              if resp.status != 200: 
                raise SystemExit(f"polygon {resp.status}")
              data = json.loads(resp.read().decode("utf-8"))

            rs = data.get("results") or []
            def mkbar(r):
              return {"t": int(r["t"]), "o": float(r["o"]), "h": float(r["h"]),
                      "l": float(r["l"]), "c": float(r["c"])}
            bars = [mkbar(r) for r in rs][-120:]  # last ~120 10m bars

            js.setdefault("series", {})
            js["series"]["SPY_10m"] = {"symbol":"SPY","timeframe":"10m","bars": bars}
            with open(SRC, "w", encoding="utf-8") as f:
              json.dump(js, f, ensure_ascii=False, separators=(",",":"))
            print(f"[inject] wrote SPY_10m bars: {len(bars)}")

          PY

      # --------------------- SANITIZE: drop any in-flight 10m bar ---------------------
      - name: Ensure CLOSED bars only (no in-flight)
        shell: bash
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, time, pathlib
          p = pathlib.Path("data/outlook_source.json")
          js = json.loads(p.read_text())

          now = int(time.time())
          BUCKET = 600
          current_bucket_start = (now // BUCKET) * BUCKET

          def looks_like_bar(o):
            if not isinstance(o, dict): return False
            has_t = ('t' in o) or ('time' in o)
            has_prices = any(k in o for k in ('o','open')) and any(k in o for k in ('h','high')) \
                         and any(k in o for k in ('l','low')) and any(k in o for k in ('c','close'))
            return has_t and has_prices

          def bar_ts(o):
            t = o.get('t', o.get('time'))
            if t is None: return None
            t = int(t)
            return t//1000 if t > 2_000_000_000 else t

          removed = [0]

          def maybe_drop_last(arr):
            if not isinstance(arr, list) or not arr: return
            last = arr[-1]
            if not looks_like_bar(last): return
            ts = bar_ts(last)
            if ts is None: return
            if (ts // BUCKET) * BUCKET == current_bucket_start:
              arr.pop(); removed[0]+=1

          def walk(x):
            if isinstance(x, dict):
              for k,v in list(x.items()):
                if k.lower()=="bars" and isinstance(v,list):
                  maybe_drop_last(v)
                else:
                  walk(v)
            elif isinstance(x,list):
              for v in x: walk(v)

          walk(js)
          p.write_text(json.dumps(js, separators=(",",":")))
          print(f"[sanitize] removed_inflight_arrays={removed[0]}")
          PY

      - name: Make dashboard payload (intraday)
        run: |
          set -euo pipefail
          echo "[timing] make_dashboard START $(date -u +%T)"
          python -u scripts/make_dashboard.py --mode intraday --source data/outlook_source.json --out data/outlook_intraday.json
          echo "[timing] make_dashboard END   $(date -u +%T)"
          jq -r '.metrics.ema_cross as $x | "ema_cross=" + ($x//"n/a") + "  ema10_dist_pct=" + ((.metrics.ema10_dist_pct//0|tonumber)|tostring) + "  updated_at=" + ((.updated_at//.updated_at_utc//"n/a")|tostring)' data/outlook_intraday.json || true

      - name: Write heartbeat_10min
        run: |
          set -e
          mkdir -p data
          date -u +'%Y-%m-%dT%H:%M:%SZ' > data/heartbeat_10min.txt

      # --------------------- Stage LIVE artifacts (to /tmp) ---------------------
      - name: Stage LIVE artifacts
        run: |
          set -e
          mkdir -p /tmp/live10
          cp -f data/outlook_intraday.json /tmp/live10/outlook_intraday.json
          cp -f data/heartbeat_10min.txt   /tmp/live10/heartbeat_10min.txt
          if [ -f data/outlook_source.json ]; then cp -f data/outlook_source.json /tmp/live10/outlook_source.json; fi

      # --------------------- Freshness gate ---------------------
      - name: Skip publish if a newer LIVE exists
        env:
          LIVE_RAW_URL: https://raw.githubusercontent.com/bfrye1973/frye-market-backend/data-live-10min/data/outlook_intraday.json
        run: |
          set -e
          OUR_TS=$(jq -r '.updated_at // .updated_at_utc // .timestamp // empty' /tmp/live10/outlook_intraday.json || true)
          if [ -z "$OUR_TS" ]; then
            echo "Could not read OUR_TS from payload; continuing publish"
            exit 0
          fi
          curl -sfL "${LIVE_RAW_URL}?t=$(date +%s)" -o /tmp/live10/current_live.json || true
          CUR_TS=$(jq -r '.updated_at // .updated_at_utc // .timestamp // empty' /tmp/live10/current_live.json 2>/dev/null || true)
          echo "our payload updated_at:  $OUR_TS"
          echo "live branch updated_at: $CUR_TS"
          if [ -n "$CUR_TS" ]; then
            A=$(date -u -d "$OUR_TS" +%s 2>/dev/null || date -u -d "${OUR_TS/Z/+00:00}" +%s 2>/dev/null || echo 0)
            B=$(date -u -d "$CUR_TS" +%s 2>/dev/null || date -u -d "${CUR_TS/Z/+00:00}" +%s 2>/dev/null || echo 0)
            echo "epoch ours=$A live=$B"
            if [ "$B" -ge "$A" ]; then
              echo "[gate] Newer or equal LIVE already present; skipping publish."
              echo "SKIP_PUBLISH=1" >> "$GITHUB_ENV"
            fi
          fi

      # --------------------- Publish LIVE branch safely ---------------------
      - name: Push LIVE branch (10min)
        if: env.SKIP_PUBLISH != '1'
        run: |
          set -e
          git config user.name  "actions-user"
          git config user.email "actions@github.com"

          git reset --hard
          git clean -fdx

          git fetch origin "${LIVE_BRANCH}" || true
          if git ls-remote --exit-code --heads origin "${LIVE_BRANCH}" >/dev/null 2>&1; then
            git checkout -B "${LIVE_BRANCH}" "origin/${LIVE_BRANCH}"
          else
            git checkout --orphan "${LIVE_BRANCH}"
          fi

          find . -mindepth 1 -maxdepth 1 ! -name ".git" -exec rm -rf {} +

          mkdir -p data
          cp -f /tmp/live10/* data/

          git add data
          git commit -m "10m live @ $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "nothing to commit"
          git push origin "${LIVE_BRANCH}"
