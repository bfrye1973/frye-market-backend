name: dashboard-hourly

on:
  workflow_dispatch: {}
  schedule:
    # Run every 40 minutes on weekdays (UTC). Pattern will be :00 → :40 → :20 → :00 …
    - cron: "*/40 * * * 1-5"

defaults:
  run:
    shell: bash

jobs:
  build_and_publish_hourly:
    name: Build and Publish Hourly (1h valuation)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    permissions:
      contents: write
    concurrency:
      group: dashboard-hourly
      cancel-in-progress: true

    env:
      TZ: America/Phoenix
      LIVE_BRANCH: data-live-hourly
      PYTHONUNBUFFERED: "1"

      # Tuning for consistency (lighter load, fewer 429s, deterministic)
      HOUR_LOOKBACK_DAYS: "10"
      H4_LOOKBACK_DAYS:   "21"
      EMA_FAST:           "8"
      EMA_SLOW:           "18"
      VOL_FAST:           "3"
      VOL_SLOW:           "12"
      FD_MAX_WORKERS:     "6"
      FD_RETRY_MAX:       "1"

    steps:
      # ---------- T0 ----------
      - name: Start timer (UTC)
        id: t0
        run: |
          echo "START_TS=$(date -u +'%Y-%m-%dT%H:%M:%SZ')" >> "$GITHUB_ENV"
          echo "T0=$(date +%s)" >> "$GITHUB_ENV"
          echo "::notice:: hourly run started at $START_TS"

      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          set -euo pipefail
          python -m pip install --upgrade pip
          pip install requests python-dateutil

      # 1) Build hourly groups → data/outlook_source.json
      - name: Build sectorCards source (hourly groups)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          ST=$(date +%s)
          mkdir -p data
          echo "::notice:: FD_MAX_WORKERS=$FD_MAX_WORKERS FD_RETRY_MAX=$FD_RETRY_MAX H1D=$HOUR_LOOKBACK_DAYS H4D=$H4_LOOKBACK_DAYS"
          python -u scripts/build_outlook_source_from_polygon.py \
            --mode hourly \
            --out data/outlook_source.json
          head -n 80 data/outlook_source.json || true
          echo "::notice:: Build hourly groups elapsed: $(( $(date +%s) - $ST ))s"

      # 2) Normalize groups → sectorCards
      - name: Normalize source (groups → sectorCards)
        run: |
          set -euo pipefail
          ST=$(date +%s)
          python - <<'PY'
          import json,sys
          path="data/outlook_source.json"
          try:
            j=json.load(open(path,"r",encoding="utf-8"))
          except Exception as e:
            print("invalid source:", e); sys.exit(1)

          def pct(a,b):
              return 0.0 if b==0 else round(100.0*float(a)/float(b),2)

          if "sectorCards" in j and isinstance(j["sectorCards"], list):
              out={"sectorCards": j["sectorCards"]}
          elif "groups" in j and isinstance(j["groups"], dict):
              groups=j["groups"]
              order=[
                "information technology","materials","health care","communication services",
                "real estate","energy","consumer staples","consumer discretionary",
                "financials","utilities","industrials",
              ]
              alias={
                "healthcare":"health care","health-care":"health care",
                "info tech":"information technology","technology":"information technology","tech":"information technology",
                "communications":"communication services","comm":"communication services","telecom":"communication services",
                "staples":"consumer staples","discretionary":"consumer discretionary",
                "finance":"financials","industry":"industrials","reit":"real estate","reits":"real estate",
              }
              def norm(s): return (s or "").strip().lower()
              bucket={}
              for raw,g in groups.items():
                  k=alias.get(norm(raw), norm(raw))
                  if not k: continue
                  nh=int(g.get("nh",0)); nl=int(g.get("nl",0)); up=int(g.get("u",0)); dn=int(g.get("d",0))
                  b=pct(nh,nh+nl); m=pct(up,up+dn)
                  bucket[k]={"sector":k.title(),"breadth_pct":b,"momentum_pct":m,"nh":nh,"nl":nl,"up":up,"down":dn}
              rows=[ bucket.get(name,{"sector":name.title(),"breadth_pct":0.0,"momentum_pct":0.0,"nh":0,"nl":0,"up":0,"down":0}) for name in order ]
              out={"sectorCards": rows}
          else:
              print("missing sectorCards/groups"); sys.exit(1)

          json.dump(out, open(path,"w",encoding="utf-8"), ensure_ascii=False)
          print("sectorCards:", len(out["sectorCards"]))
          print("sample:", out["sectorCards"][:3])
          PY
          echo "::notice:: Normalize elapsed: $(( $(date +%s) - $ST ))s"

      # 3) Compose 1h + 4h meter → data/outlook_hourly.json
      - name: Build hourly payload (1h + 4h)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          HOUR_LOOKBACK_DAYS: ${{ env.HOUR_LOOKBACK_DAYS }}
          H4_LOOKBACK_DAYS:   ${{ env.H4_LOOKBACK_DAYS }}
          EMA_FAST:           ${{ env.EMA_FAST }}
          EMA_SLOW:           ${{ env.EMA_SLOW }}
          VOL_FAST:           ${{ env.VOL_FAST }}
          VOL_SLOW:           ${{ env.VOL_SLOW }}
        run: |
          set -euo pipefail
          ST=$(date +%s)
          python -u scripts/make_dashboard_hourly.py \
            --source data/outlook_source.json \
            --out    data/outlook_hourly.json
          echo "::notice:: Payload build elapsed: $(( $(date +%s) - $ST ))s"

      # 4) Lux hook
      - name: Compute Lux strategy (1h)
        run: |
          set -euo pipefail
          ST=$(date +%s)
          python -u scripts/compute_trend_hourly.py
          echo "::notice:: Lux compute elapsed: $(( $(date +%s) - $ST ))s"

      # 5) Safety: ensure minimum 1h signals
      - name: Ensure 1h signals (safe)
        run: |
          set -euo pipefail
          python - <<'PY'
          import json, datetime
          path="data/outlook_hourly.json"
          j=json.load(open(path,"r",encoding="utf-8"))
          def now(): return datetime.datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
          hourly=j.get("hourly") or {}
          signals=hourly.get("signals") or {}
          def setif(k, st="neutral"):
              s=signals.get(k) or {}
              s.setdefault("state",st)
              s.setdefault("lastChanged",now())
              signals[k]=s
          overall=(hourly.get("overall1h") or {}).get("state") or "neutral"
          setif("sigOverall1h", str(overall).lower())
          hourly["signals"]=signals
          j["hourly"]=hourly
          json.dump(j,open(path,"w",encoding="utf-8"),ensure_ascii=False,separators=(",",":"))
          print("[safe] signals:", list(signals.keys()))
          PY

      # 6) Validate structure
      - name: Validate required keys
        run: |
          set -euo pipefail
          python - <<'PY'
          import json,sys
          j=json.load(open("data/outlook_hourly.json","r",encoding="utf-8"))
          m=j.get("metrics") or {}
          for k in ["breadth_1h_pct","momentum_1h_pct","squeeze_1h_pct","liquidity_1h","volatility_1h_pct"]:
            if k not in m:
              print("missing metric:",k); sys.exit(1)
          sc=j.get("sectorCards") or []
          if not sc or not isinstance(sc,list) or len(sc)!=11:
            print("missing/invalid sectorCards:",len(sc)); sys.exit(1)
          print("OK: metrics & sectorCards present")
          PY

      - name: Write heartbeat
        run: date -u +"%Y-%m-%dT%H:%M:%SZ" > data/heartbeat_1h

      # 7) Publish only when changed
      - name: Detect change
        id: diff
        env:
          LIVE_BRANCH: ${{ env.LIVE_BRANCH }}
        run: |
          set -euo pipefail
          CHANGED="true"
          if git ls-remote --exit-code --heads origin "${LIVE_BRANCH}" >/dev/null 2>&1; then
            git fetch --no-tags --depth=1 origin "${LIVE_BRANCH}"
            git show "origin/${LIVE_BRANCH}:data/outlook_hourly.json" > /tmp/prev.json 2>/dev/null || true
            if [ -s /tmp/prev.json ] && cmp -s /tmp/prev.json data/outlook_hourly.json; then
              CHANGED="false"
            fi
          fi
          echo "changed=${CHANGED}" >> "$GITHUB_OUTPUT"

      - name: Publish live branch (safe)
        if: ${{ steps.diff.outputs.changed == 'true' }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          LIVE_BRANCH: ${{ env.LIVE_BRANCH }}
        run: |
          set -euo pipefail
          git config user.email "user@local"
          git config user.name  "CI Bot"
          git fetch --depth=1 origin "${LIVE_BRANCH}" || true
          git checkout -B "${LIVE_BRANCH}" "origin/${LIVE_BRANCH}" || git checkout -B "${LIVE_BRANCH}"
          mkdir -p /tmp/push
          cp -f data/outlook_hourly.json /tmp/push/outlook_hourly.json
          cp -f data/heartbeat_1h      /tmp/push/heartbeat_1h
          git rm -rf data || true
          mkdir -p data
          mv /tmp/push/* data/
          git add -A
          if git diff --cached --quiet; then
            echo "no changes to commit"
          else:
            git commit -m "hourly publish $(date -u +'%Y-%m-%dT%H:%M:%SZ')"
            git push -f origin "${LIVE_BRANCH}"
          fi
