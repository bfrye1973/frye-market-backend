name: dashboard-hourly

on:
  workflow_dispatch: {}
  schedule:
    # Top of each hour during US market hours (13:00–20:00 UTC), Mon–Fri
    - cron: "0 13-20 * * 1-5"

concurrency:
  group: data-writes-hourly
  cancel-in-progress: true

jobs:
  hourly:
    name: Build & Publish (Hourly)
    runs-on: ubuntu-latest
    timeout-minutes: 60
    permissions:
      contents: write
    env:
      TZ: America/Phoenix
      LIVE_BRANCH: data-live-hourly
      ARCHIVE_BRANCH: data-archive-hourly

    steps:
      # ---------------------- Repo Setup ----------------------
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Sync refs
        run: |
          git fetch origin +refs/heads/*:refs/remotes/origin/*

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install jq || true

      # ---------------------- Verify Polygon Key ----------------------
      - name: Verify POLYGON_API_KEY is present
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          echo "::group::Verify POLYGON_API_KEY"
          if [ -z "${POLYGON_API_KEY:-}" ]; then
            echo "[error] POLYGON_API_KEY is empty or not set in GitHub Actions secrets."
            echo "Go to: GitHub → repo Settings → Secrets and variables → Actions → New secret → name=POLYGON_API_KEY, value=<your key>"
            exit 1
          fi
          # Mask the key and show its length only
          echo "::add-mask::${POLYGON_API_KEY}"
          echo "[ok] POLYGON_API_KEY length: ${#POLYGON_API_KEY}"
          echo "::endgroup::"

      # ---------------------- Probe Polygon (fast fail) ----------------------
      - name: Probe Polygon API (auth + plan)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
        run: |
          set -euo pipefail
          echo "::group::Polygon probe"
          PROBE_URL="https://api.polygon.io/v2/aggs/ticker/SPY/prev?adjusted=true&apiKey=${POLYGON_API_KEY}"
          HTTP=$(curl -sS -w "%{http_code}" -o /tmp/probe.json "${PROBE_URL}" || true)
          echo "[probe] HTTP=${HTTP}"
          echo "[probe] body:"
          tail -c 800 /tmp/probe.json || true
          echo "::endgroup::"

          case "${HTTP}" in
            200) echo "[ok] Polygon probe passed (200)";;
            401|403)
              echo "[error] Polygon authentication failed (HTTP ${HTTP}). Check that POLYGON_API_KEY is correct and active."
              exit 1
              ;;
            429)
              echo "[warn] Rate limited (429). The build may still work with retries, but consider reducing hourly lookback/symbols."
              ;;
            5*)
              echo "[warn] Polygon server error (HTTP ${HTTP}). Will continue with retry safeguards."
              ;;
            *)
              echo "[info] Unexpected HTTP ${HTTP} — continuing."
              ;;
          esac

      # ---------------------- Build (Hourly) ----------------------
      # Full logging + 2-try retry to expose the real error cause (no hard timeout).
      - name: Build outlook source (hourly)
        env:
          POLYGON_API_KEY: ${{ secrets.POLYGON_API_KEY }}
          PYTHONUNBUFFERED: "1"
        run: |
          set -euo pipefail
          echo "[timing] build_outlook_source START $(date -u +%T)"
          tries=0
          while : ; do
            set +e
            python -u scripts/build_outlook_source_from_polygon.py --mode hourly 2>&1 | tee /tmp/hourly_build.log
            rc=${PIPESTATUS[0]}
            set -e
            if [ "$rc" -eq 0 ]; then
              echo "[timing] build_outlook_source END   $(date -u +%T)"
              break
            fi

            tries=$((tries+1))
            echo "[warn] build_outlook_source failed rc=$rc (try $tries/2)"
            echo "----- LOG (tail) -----"
            tail -n 200 /tmp/hourly_build.log || true
            echo "----------------------"

            if [ "$tries" -ge 2 ]; then
              echo "[error] giving up after $tries tries"
              exit "$rc"
            fi

            sleep 30
          done

          test -s data/outlook_source.json
          echo "[info] outlook_source.json size: $(wc -c < data/outlook_source.json) bytes"

      # ---------------------- Make Dashboard Payload ----------------------
      - name: Make dashboard payload (hourly)
        run: |
          set -euo pipefail
          echo "[timing] make_dashboard START $(date -u +%T)"
          python -u scripts/make_dashboard.py --mode hourly --source data/outlook_source.json --out data/outlook_hourly.json
          echo "[timing] make_dashboard END   $(date -u +%T)"
          test -s data/outlook_hourly.json
          jq -r '.metrics.ema_cross as $x
            | "ema_cross=" + ($x//"n/a")
            + "  ema10_dist_pct=" + ((.metrics.ema10_dist_pct//0|tonumber)|tostring)
            + "  updated_at=" + ((.updated_at//.updated_at_utc//"n/a")|tostring)' \
            data/outlook_hourly.json || true

      # ---------------------- Heartbeat ----------------------
      - name: Write heartbeat_hourly
        run: |
          set -e
          mkdir -p data
          date -u +'%Y-%m-%dT%H:%M:%SZ' > data/heartbeat_hourly.txt

      # ---------------------- Stage Files ----------------------
      - name: Stage files for publish
        id: prep
        run: |
          set -e
          RAW_TS=$(jq -r '.updated_at // .ts // .updated_at_utc' data/outlook_hourly.json)
          TS_SAFE=$(printf '%s' "$RAW_TS" | sed 's/[: ]/-/g')
          echo "RAW_TS=$RAW_TS"
          echo "TS_SAFE=$TS_SAFE"

          mkdir -p /tmp/live /tmp/archive/source /tmp/archive/dashboard

          # LIVE "latest"
          cp -f data/outlook_hourly.json /tmp/live/
          cp -f data/outlook_source.json  /tmp/live/
          cp -f data/heartbeat_hourly.txt /tmp/live/

          # ARCHIVE snapshots
          cp -f data/outlook_source.json  "/tmp/archive/source/outlook_source_${TS_SAFE}.json"
          cp -f data/outlook_hourly.json  "/tmp/archive/dashboard/outlook_hourly_${TS_SAFE}.json"

          echo "ts=${TS_SAFE}" >> "$GITHUB_OUTPUT"

      # ---------------------- Publish LIVE ----------------------
      - name: Push LIVE branch (hourly)
        run: |
          set -e
          git config user.name  "actions-user"
          git config user.email "actions@github.com"

          if git show-ref --verify --quiet refs/heads/"$LIVE_BRANCH"; then
            git checkout "$LIVE_BRANCH"
          else
            git checkout --orphan "$LIVE_BRANCH"
          fi

          git rm -rf . || true
          mkdir -p data
          cp -f /tmp/live/* data/
          git add data
          git commit -m "HOURLY live: $(date -u +'%Y-%m-%dT%H:%M:%SZ')" || echo "nothing to commit (live)"
          git push origin +HEAD:"$LIVE_BRANCH"

      # ---------------------- Publish ARCHIVE ----------------------
      - name: Push ARCHIVE branch (append)
        run: |
          set -e
          git config user.name  "actions-user"
          git config user.email "actions@github.com"

          git fetch origin "$ARCHIVE_BRANCH" || true
          if git show-ref --verify --quiet refs/heads/"$ARCHIVE_BRANCH"; then
            git checkout "$ARCHIVE_BRANCH"
          else
            git checkout -b "$ARCHIVE_BRANCH" "origin/$ARCHIVE_BRANCH" 2>/dev/null || git checkout --orphan "$ARCHIVE_BRANCH"
          fi

          mkdir -p data/archive/hourly/source data/archive/hourly/dashboard
          cp -f /tmp/archive/source/*    data/archive/hourly/source/    || true
          cp -f /tmp/archive/dashboard/* data/archive/hourly/dashboard/ || true
          git add data/archive/hourly || true
          git commit -m "HOURLY archive: ${{ steps.prep.outputs.ts }}" || echo "nothing to commit (archive)"

          git pull --rebase origin "$ARCHIVE_BRANCH" || true
          git push origin HEAD:"$ARCHIVE_BRANCH"
